{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Trend for hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_KEY = \"xxx\"\n",
    "SECRET_KEY = \"xxx\".replace(\"/\", \"%2F\")\n",
    "AWS_BUCKET_NAME = \"project4capstones3\"\n",
    "MOUNT_NAME = \"twitter_19038028888888\"\n",
    "\n",
    "dbutils.fs.mount(\"s3a://%s:%s@%s\" % (ACCESS_KEY, SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % MOUNT_NAME)\n",
    "\n",
    "display(dbutils.fs.ls(\"/mnt/%s\" % MOUNT_NAME))\n",
    "\n",
    "import json\n",
    "# input = sc.textFile(\"/mnt/twitter/2017/06/*/*/project*\")\n",
    "data = sqlContext.read.json(\"/mnt/twitter/2017/06/*/*/project*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.select('status_created_at', 'searched_names', 'status_sentScore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def dt_parse(datetime_str):\n",
    "  dt_tz = datetime_str.split()\n",
    "  dt_str, tz_str = ' '.join(dt_tz[:4] + dt_tz[5:]), dt_tz[4]\n",
    "  dt = datetime.strptime(dt_str, '%c')\n",
    "  if tz_str[0] == '+':\n",
    "    dt += timedelta(hours=int(tz_str[1:3]), minutes=int(tz_str[3:]))\n",
    "  elif tz_str[0] == '-':\n",
    "    dt -= timedelta(hours=int(tz_str[1:3]), minutes=int(tz_str[3:]))\n",
    "  return dt #.strftime(format='%Y-%M-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import TimestampType\n",
    "dt_parse_udf =  udf(dt_parse, TimestampType())\n",
    "\n",
    "df_final = df.withColumn('status_created_at', dt_parse_udf(df['status_created_at']))\n",
    "# df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import hour, dayofyear\n",
    "\n",
    "df_trend = df_final.select(dayofyear('status_created_at').alias('day'),hour('status_created_at').alias('hour'), \"status_sentScore\", 'searched_names').groupby('day', 'hour', 'searched_names').agg({\"*\":\"count\", \"status_sentScore\":\"avg\"}).sort('day', 'hour').withColumnRenamed(\"count(1)\", \"Tweet_Cnt\").withColumnRenamed(\"avg(status_sentScore)\", \"Avg_Sent_Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat, col, lit\n",
    "\n",
    "# merging day and hour column and adding it as extra column\n",
    "df_trend_final = df_trend.withColumn(\"day_hour\", concat(col(\"day\"),col(\"hour\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StructType, StringType\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trend_final.write.saveAsTable('trend_df', mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import hour, dayofyear\n",
    "# display(df_final.select(hour('status_created_at').alias('hour'), dayofyear('status_created_at').alias('day')).groupby('hour', 'day').count().sort('day', 'hour'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "name": "Test",
  "notebookId": 3.708479553025694E15
 },
 "nbformat": 4,
 "nbformat_minor": 0
}